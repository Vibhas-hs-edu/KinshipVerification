{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Kinship Recognition Starter Notebook.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"P4g8yMLqtS3W"},"source":["# **Large-Scale Kinship Recognition Data Challenge: Kinship Verification STARTER NOTEBOOK**\n","\n","We provide framework code to get you started on the competition. The notebook is broken up into three main sections. \n","1. Data Loading & Visualizing\n","2. Data Generator & Model Building\n","3. Training & Testing Model\n","\n","We have done the majority of the heavy lifting by making the data easily and readily accessible through Google Drive. Furthermore, we have made the task easier by creating a dataloader and fully trained end-to-end model that predicts a binary label (0 or 1) denoting whether two faces share a kinship relation. "]},{"cell_type":"markdown","metadata":{"id":"9LDDgTAe2w0H"},"source":["**WARNING: IF YOU HAVE NOT DONE SO**\n","\n","Change to GPU:\n","\n","Runtime --> Change Runtime Type --> GPU"]},{"cell_type":"markdown","metadata":{"id":"mWf8L2-Ru6ZE"},"source":["Mount to Google Drive"]},{"cell_type":"markdown","metadata":{"id":"ribPmcZau-vR"},"source":["Install Libraries"]},{"cell_type":"code","metadata":{"id":"tS3ZhSjIAGgt","executionInfo":{"status":"ok","timestamp":1628793249360,"user_tz":-330,"elapsed":14004,"user":{"displayName":"Vibhas Naik","photoUrl":"","userId":"08603031012526988895"}}},"source":["%%capture\n","!pip install mxnet\n","!pip install mxnet-cu101\n","!pip install insightface\n","!pip install gluonfr\n","!pip install onnxruntime\n","!pip install opencv-python"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nzChENDGzwCD"},"source":["Mount your google drive"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m4yFxckrAAZx","executionInfo":{"status":"ok","timestamp":1628793250462,"user_tz":-330,"elapsed":1111,"user":{"displayName":"Vibhas Naik","photoUrl":"","userId":"08603031012526988895"}},"outputId":"09e205f0-a1e8-46e5-a4a9-53d36affdbac"},"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount= True)"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ju4RYMR80GFb","executionInfo":{"status":"ok","timestamp":1628793252276,"user_tz":-330,"elapsed":1821,"user":{"displayName":"Vibhas Naik","photoUrl":"","userId":"08603031012526988895"}}},"source":["import mxnet as mx\n","import numpy as np\n","from mxnet import gluon\n","from mxnet import autograd as ag\n","from mxnet.gluon.data.vision import transforms\n","from insightface.utils.face_align import norm_crop\n","import cv2\n","from mxnet.gluon.data import Dataset\n","\n","import time\n","import gluonfr\n","from pathlib import Path\n","import os\n","from tqdm import tqdm\n","\n","import random\n","from pathlib import Path\n","from typing import Tuple, Optional, Generator, Any, List, Union, Callable"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dD3drf8m01Ae"},"source":["**All Paths used for training and testing**"]},{"cell_type":"code","metadata":{"id":"1EmTb9Ge00TE","executionInfo":{"status":"ok","timestamp":1628793252289,"user_tz":-330,"elapsed":22,"user":{"displayName":"Vibhas Naik","photoUrl":"","userId":"08603031012526988895"}}},"source":["root = '/content/drive/My Drive/DeepLearning/KaggleCompetition'\n","train_path = Path(os.path.join(root, 'train-faces-processed'))\n","pre_trained_models_path = Path(os.path.join(root, 'pre_trained_models'))"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"a19NnsoixzWk","executionInfo":{"status":"ok","timestamp":1628793252291,"user_tz":-330,"elapsed":22,"user":{"displayName":"Vibhas Naik","photoUrl":"","userId":"08603031012526988895"}}},"source":["Img = np.ndarray # HxWxC image in numpy (read with cv2.imread\n","MxImg = mx.nd.NDArray  # HxWxC image in mxnet (read with mx.img.imread or converted from Img)\n","Embedding = mx.nd.NDArray  # 1x512 image embedding (CNN output given input image)\n","MxImgArray = mx.nd.NDArray  # NxCxHxW batch of input images\n","Labels = mx.nd.NDArray  # Nx1 float unscaled kinship relation labels\n","ImgOrPath = Union[Img, Path]\n","ImgPairOrPath = Tuple[ImgOrPath, ImgOrPath]\n","PairPath = Tuple[Path, Path]"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Hj6F6Dp8z2i0"},"source":["**Generate your own train_ds.csv**\n","\n","train_ds.csv has three columns.\n","\n","\n","1.   Path of the image\n","2.   Person Id\n","3.   Family Id\n","\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"Y4pwVBRj0qi9","executionInfo":{"status":"ok","timestamp":1628793252293,"user_tz":-330,"elapsed":22,"user":{"displayName":"Vibhas Naik","photoUrl":"","userId":"08603031012526988895"}}},"source":["families = [[cur_person for cur_person in cur_family.iterdir()\n","                    if cur_person.is_dir()]\n","                    for cur_family in train_path.iterdir()]"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z_jyqo72uM2R","executionInfo":{"status":"ok","timestamp":1628793252937,"user_tz":-330,"elapsed":665,"user":{"displayName":"Vibhas Naik","photoUrl":"","userId":"08603031012526988895"}}},"source":["seq = [(img_path,  family_idx, person_idx)\n","                  for family_idx, cur_family in enumerate(families)\n","                  for person_idx, cur_person in enumerate(cur_family)\n","                  for img_path in cur_person.iterdir()]"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8fv2-GKgi8xI","executionInfo":{"status":"ok","timestamp":1628793252938,"user_tz":-330,"elapsed":20,"user":{"displayName":"Vibhas Naik","photoUrl":"","userId":"08603031012526988895"}},"outputId":"a0e6f89c-3706-43f5-fb33-41c0e86d6f1a"},"source":["print(len(seq))"],"execution_count":8,"outputs":[{"output_type":"stream","text":["5037\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"tsiOpAGWwPSf","executionInfo":{"status":"ok","timestamp":1628793252941,"user_tz":-330,"elapsed":17,"user":{"displayName":"Vibhas Naik","photoUrl":"","userId":"08603031012526988895"}}},"source":["class FamiliesDataset(Dataset):\n","  def __init__(self):\n","    super(FamiliesDataset, self).__init__()\n","\n","  def __getitem__(self, idx : int) -> Tuple[MxImg, int, int]:\n","    img_path, family_idx, person_idx = seq[idx]\n","    img = mx.img.imread(str(img_path))\n","    return img, family_idx, person_idx\n","    \n","  def __len__(self) -> int:\n","    return len(seq)"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"MKwEKid_zFNk","executionInfo":{"status":"ok","timestamp":1628793253486,"user_tz":-330,"elapsed":559,"user":{"displayName":"Vibhas Naik","photoUrl":"","userId":"08603031012526988895"}}},"source":["def train(normalize : bool = False):\n","  train_dataset = FamiliesDataset()\n","  jitter_param = 0.15\n","  lighting_param = 0.15\n","  batch_size = 48\n","  num_workers = 12\n","  model_name = 'arcface_r100_v1'\n","  net_name = 'arcface_families_ft'\n","\n","  arc_r_100_path = os.path.join(pre_trained_models_path, 'arcface_r100')\n","  sym_path = os.path.join(arc_r_100_path, 'model-symbol.json')\n","  weight_path = os.path.join(arc_r_100_path, 'model-0000.params')\n","\n","  snapshots_path = Path(os.path.join(root, 'my_trained_models'))\n","  if not os.path.exists(str(snapshots_path)):\n","        os.makedirs(str(snapshots_path))\n","  num_families = len(families)\n","\n","  warmup = 200\n","  lr = 1e-4\n","  cooldown = 400\n","  lr_factor = 0.75\n","  num_epoch = 50\n","  momentum = 0.9\n","  wd = 1e-4\n","  clip_gradient = 1.0\n","  lr_steps = [8, 14, 25, 35, 40, 50, 60]\n","  ctx_list = [mx.gpu()]\n","\n","  transform_img_train = transforms.Compose([\n","  transforms.RandomColorJitter(brightness=jitter_param, contrast = jitter_param, saturation= jitter_param),\n","  transforms.RandomLighting(lighting_param),\n","  #ReJPGTransform(0.3, 70),\n","  transforms.ToTensor()\n","  ])\n","\n","  train_data = mx.gluon.data.DataLoader(\n","      train_dataset.transform_first(transform_img_train),\n","      shuffle = True,\n","      batch_size = batch_size,\n","      num_workers = num_workers,\n","      pin_memory = True\n","  )\n","  ctx = ctx_list[0]\n","  print('Load symbols')\n","  sym = mx.sym.load(str(sym_path))\n","  print('Loaded symbols')\n","  if normalize:\n","    norm_sym = mx.sym.sqrt(sum(sym ** 2, axis = 1, keepdims = True) + 1e-06)\n","    sym = mx.sym.broadcast_div(sym, norm_sym, name = 'fc_normed') * 32\n","  sym = mx.sym.FullyConnected(sym, num_hidden = num_families, name = 'fc_classification', lr_mult = 1)\n","  net = gluon.SymbolBlock([sym], [mx.sym.var('data')])\n","  net.load_parameters(str(weight_path), ctx = ctx, cast_dtype=True,\n","                      allow_missing=True, ignore_extra=False)\n","  net.initialize(mx.init.Normal(), ctx=mx.cpu())\n","  net.collect_params().reset_ctx(ctx)\n","  net.hybridize()\n","\n","  all_losses = [\n","                ('softmax', gluon.loss.SoftmaxCrossEntropyLoss()),\n","                #('arc', gluonfr.loss.ArcLoss(num_families, m=0.7, s=32, easy_margin=False)), \n","                #('center', gluonfr.loss.CenterLoss(num_families, 512, 1e-1))\n","                ]\n","  \n","\n","  start_lr = 1e-10\n","  warmup_iter = 0\n","  end_iter = num_epoch * len(train_data)\n","  cooldown_start = end_iter - cooldown\n","  cooldown_iter = 0\n","  end_lr = 1e-10\n","  param_dict = net.collect_params()\n","  trainer = mx.gluon.Trainer(param_dict, 'sgd', {\n","      'learning_rate': start_lr, 'momentum': momentum, 'wd': wd, 'clip_gradient': clip_gradient})\n","  lr_counter = 0\n","  num_batch = len(train_data)\n","\n","  for epoch in range(num_epoch):\n","    if epoch == lr_steps[lr_counter]:\n","      trainer.set_learning_rate(trainer.learning_rate*lr_factor)\n","      lr_counter += 1\n","\n","    tic = time.time()\n","    losses = [0] * len(all_losses)\n","    metric = mx.metric.Accuracy()\n","    print(' > training', epoch)\n","    metric = mx.metric.Accuracy()\n","    print(' > training', epoch)\n","    for i, batch in tqdm(enumerate(train_data), total=len(train_data)):\n","      if warmup_iter < warmup:\n","        cur_lr = (warmup_iter + 1) * (lr - start_lr) / warmup + start_lr\n","        trainer.set_learning_rate(cur_lr)\n","        warmup_iter += 1\n","      elif cooldown_iter > cooldown_start:\n","        cur_lr = (end_iter - cooldown_iter) * (trainer.learning_rate - end_lr) / cooldown + end_lr\n","        trainer.set_learning_rate(cur_lr)\n","      cooldown_iter += 1\n","\n","      data = mx.gluon.utils.split_and_load(batch[0] * 255, ctx_list=ctx_list, even_split=False)\n","      gts = mx.gluon.utils.split_and_load(batch[1], ctx_list=ctx_list, even_split=False)\n","\n","      with ag.record():\n","        outputs = [net(X) for X in data]\n","        if np.any([np.any(np.isnan(o.asnumpy())) for os in outputs for o in os]):\n","          print('OOps!')\n","          raise RuntimeError\n","        cur_losses = [[cur_loss(o, l) for (o, l) in zip(outputs, gts)] for _, cur_loss in all_losses]\n","        metric.update(gts, outputs)\n","        combined_losses = [cur[0] for cur in zip(*cur_losses)]\n","        if np.any([np.any(np.isnan(l.asnumpy())) for l in cur_losses[0]]):\n","          print('OOps2!')\n","          raise RuntimeError\n","      for combined_loss in combined_losses:\n","        combined_loss.backward()\n","      \n","      trainer.step(batch_size, ignore_stale_grad=True)\n","      for idx, cur_loss in enumerate(cur_losses):\n","        losses[idx] += sum([l.mean().asscalar() for l in cur_loss]) / len(cur_loss)\n","\n","    if (epoch + 1) % 10 == 0:\n","      net.export(f'{str(snapshots_path)}/export_{net_name}', epoch = epoch + 1)\n","\n","    losses = [l / num_batch for l in losses]\n","    losses_str = [f'{l_name}: {losses[idx]:.3f}' for idx, (l_name, _) in enumerate(all_losses)]\n","    losses_str = '; '.join(losses_str)\n","    m_name, m_val = metric.get()\n","    losses_str += f'| {m_name}: {m_val}'\n","    print(f'[Epoch {epoch:03d}] {losses_str} | time: {time.time() - tic:.1f}')"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HIpSFFXpI-_H","outputId":"7f8fd568-eff5-4546-de76-474406315930"},"source":["if __name__ == '__main__':\n","    np.random.seed(100)\n","    mx.random.seed(100)\n","    train(normalize=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["100%|██████████| 105/105 [01:14<00:00,  1.40it/s]\n","  0%|          | 0/105 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["[Epoch 010] softmax: 4.725| accuracy: 0.3527893587452849 | time: 74.9\n"," > training 11\n"," > training 11\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 105/105 [01:14<00:00,  1.40it/s]\n","  0%|          | 0/105 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["[Epoch 011] softmax: 4.672| accuracy: 0.39031169346833433 | time: 74.8\n"," > training 12\n"," > training 12\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 105/105 [01:14<00:00,  1.40it/s]\n","  0%|          | 0/105 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["[Epoch 012] softmax: 4.616| accuracy: 0.42306928727417115 | time: 74.9\n"," > training 13\n"," > training 13\n"],"name":"stdout"},{"output_type":"stream","text":[" 73%|███████▎  | 77/105 [00:55<00:19,  1.41it/s]"],"name":"stderr"}]}]}